{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hedging as a BSDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep BSDE\n",
    "Hedging option can be formulated as a BSDE problem:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is copy pasted and modified from:\n",
    "https://github.com/YifanJiang233/Deep_BSDE_solver/tree/master.\n",
    "\n",
    "Do I have to add a MIT license?\n",
    "\n",
    "Note that the paper \n",
    "\n",
    "[1] E, W., Han, J., and Jentzen, A. Deep learning-based numerical methods for high-dimensional parabolic partial differential equations and backward stochastic differential equations, Communications in Mathematics and Statistics, 5, 349â€“380 (2017).\n",
    "\n",
    "is referenced but no subnetworks are used but a network that also takes in time. \n",
    "The actual implementation is for \n",
    "\n",
    "https://arxiv.org/pdf/2101.01869.pdf\n",
    "\n",
    "[2] Jiang,Y., Li, J. Convergence of the deep bsde method for fbsdes with non-lipschitz coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from parameterfree import COCOB\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable,List\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "@dataclass\n",
    "class fbsde_parameters:\n",
    "    S0: torch.Tensor\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    f: Callable\n",
    "    g: Callable\n",
    "    T: float\n",
    "    dim_x: int\n",
    "    dim_y: int\n",
    "    dim_d: int\n",
    "    guess_sol: List[int]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.S0 = self.S0.to(device)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, fbsde_parameters, dim_h):\n",
    "        super(Model, self).__init__()\n",
    "        self.equation= fbsde_parameters\n",
    "\n",
    "        # specifying parameters of NN\n",
    "        l = torch.rand(fbsde_parameters.dim_y, device=device)\n",
    "        self.y_0 = nn.Parameter(fbsde_parameters.guess_sol[0]*l+ fbsde_parameters.guess_sol[1]*(1-l))\n",
    "        self.linear1 = nn.Linear(fbsde_parameters.dim_x+1, dim_h) # dim_x + 1  the extra 1 for time\n",
    "        self.linear2 = nn.Linear(dim_h, dim_h)\n",
    "        self.linear3 = nn.Linear(dim_h, dim_h)\n",
    "        self.linear4 = nn.Linear(dim_h, fbsde_parameters.dim_y*fbsde_parameters.dim_d)\n",
    "        self.bn1 =nn.BatchNorm1d(dim_h)\n",
    "        self.bn2 =nn.BatchNorm1d(dim_h)\n",
    "    \n",
    "    def get_z(self,x,t):\n",
    "        output = torch.cat((x, t*torch.ones(x.size()[0], 1,device=device)), 1)\n",
    "        output = F.gelu(self.linear1(output))\n",
    "        output = self.bn1(F.gelu(self.linear2(output)))\n",
    "        output = self.bn2(F.gelu(self.linear3(output)))\n",
    "        return self.linear4(output).reshape(-1, self.equation.dim_y, self.equation.dim_d)\n",
    "        \n",
    "\n",
    "    def forward(self,batch_size, N):\n",
    "        dt = self.equation.T / N\n",
    "        x = self.equation.S0+torch.zeros(batch_size,self.equation.dim_x,device=device)\n",
    "        y = self.y_0+torch.zeros(batch_size,self.equation.dim_y,device=device)\n",
    "\n",
    "        for i in range(N):\n",
    "            t = dt*i\n",
    "            z = self.get_z(x,t)\n",
    "\n",
    "            dW = torch.randn(batch_size, self.equation.dim_d, 1, device=device) * np.sqrt(dt)\n",
    "            x = x+self.equation.mu(t, x, y)*dt+torch.matmul( self.equation.sigma(t, x), dW).reshape(-1, self.equation.dim_x)\n",
    "            y = y-self.equation.f(t, x, y, z)*dt + torch.matmul(z, dW).reshape(-1, self.equation.dim_y)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "class BSDEsolver():\n",
    "    def __init__(self, equation, model):\n",
    "        self.model = model \n",
    "        self.equation = equation\n",
    "\n",
    "    def train(self, batch_size, N, itr, log):\n",
    "        loss_fun = torch.nn.MSELoss().to(device)\n",
    "        # optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        optimizer = COCOB(self.model.parameters())\n",
    "        loss_data, y0_data = [], []\n",
    "\n",
    "        for i in range(itr):\n",
    "            x, y = self.model(batch_size,N)\n",
    "            loss = loss_fun(self.equation.g(x), y)\n",
    "            loss_data.append(float(loss))\n",
    "            y0_data.append(float(self.model.y_0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if log  and i%int(itr/20) == 0:\n",
    "                print(f\"loss: {float(loss):7.2f} y0: {float(self.model.y_0):7.2f} done: {i/itr*100:5.2f}% Iteration: {i}\")\n",
    "        return loss_data, y0_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time discretization: 2 Batch size: 1000 Iterations: 100\n",
      "loss:  310.19 y0:    9.48 done:  0.00% Iteration: 0\n",
      "loss:  329.69 y0:    9.53 done:  5.00% Iteration: 5\n",
      "loss:  306.79 y0:    9.61 done: 10.00% Iteration: 10\n",
      "loss:  334.30 y0:    9.81 done: 15.00% Iteration: 15\n",
      "loss:  273.51 y0:   10.28 done: 20.00% Iteration: 20\n",
      "loss:  144.78 y0:   11.21 done: 25.00% Iteration: 25\n",
      "loss:   55.34 y0:   12.33 done: 30.00% Iteration: 30\n",
      "loss:   55.27 y0:   13.43 done: 35.00% Iteration: 35\n",
      "loss:   54.35 y0:   13.68 done: 40.00% Iteration: 40\n",
      "loss:   48.96 y0:   13.76 done: 45.00% Iteration: 45\n",
      "loss:   50.08 y0:   13.80 done: 50.00% Iteration: 50\n",
      "loss:   53.10 y0:   13.87 done: 55.00% Iteration: 55\n",
      "loss:   47.25 y0:   13.79 done: 60.00% Iteration: 60\n",
      "loss:   48.25 y0:   14.03 done: 65.00% Iteration: 65\n",
      "loss:   60.10 y0:   13.87 done: 70.00% Iteration: 70\n",
      "loss:   51.81 y0:   13.66 done: 75.00% Iteration: 75\n",
      "loss:   54.06 y0:   13.72 done: 80.00% Iteration: 80\n",
      "loss:   49.30 y0:   13.66 done: 85.00% Iteration: 85\n",
      "loss:   56.88 y0:   13.82 done: 90.00% Iteration: 90\n",
      "loss:   51.31 y0:   13.90 done: 95.00% Iteration: 95\n",
      "============================================================\n",
      "Time discretization: 10 Batch size: 1000 Iterations: 100\n",
      "loss:   21.03 y0:   13.79 done:  0.00% Iteration: 0\n",
      "loss:   17.71 y0:   13.82 done:  5.00% Iteration: 5\n",
      "loss:   18.46 y0:   13.85 done: 10.00% Iteration: 10\n",
      "loss:   17.97 y0:   13.88 done: 15.00% Iteration: 15\n",
      "loss:   18.05 y0:   13.94 done: 20.00% Iteration: 20\n",
      "loss:   18.79 y0:   13.99 done: 25.00% Iteration: 25\n",
      "loss:   18.63 y0:   14.02 done: 30.00% Iteration: 30\n",
      "loss:   18.19 y0:   14.06 done: 35.00% Iteration: 35\n",
      "loss:   16.93 y0:   14.07 done: 40.00% Iteration: 40\n",
      "loss:   16.96 y0:   14.07 done: 45.00% Iteration: 45\n",
      "loss:   16.67 y0:   14.05 done: 50.00% Iteration: 50\n",
      "loss:   16.93 y0:   14.03 done: 55.00% Iteration: 55\n",
      "loss:   17.87 y0:   14.07 done: 60.00% Iteration: 60\n",
      "loss:   17.63 y0:   14.04 done: 65.00% Iteration: 65\n",
      "loss:   18.39 y0:   14.05 done: 70.00% Iteration: 70\n",
      "loss:   18.45 y0:   14.05 done: 75.00% Iteration: 75\n",
      "loss:   15.51 y0:   14.07 done: 80.00% Iteration: 80\n",
      "loss:   16.86 y0:   14.03 done: 85.00% Iteration: 85\n",
      "loss:   17.39 y0:   14.06 done: 90.00% Iteration: 90\n",
      "loss:   15.90 y0:   14.06 done: 95.00% Iteration: 95\n",
      "============================================================\n",
      "Time discretization: 40 Batch size: 1000 Iterations: 100\n",
      "loss:   10.30 y0:   14.05 done:  0.00% Iteration: 0\n",
      "loss:    9.99 y0:   14.08 done:  5.00% Iteration: 5\n",
      "loss:    8.49 y0:   14.09 done: 10.00% Iteration: 10\n",
      "loss:    9.16 y0:   14.08 done: 15.00% Iteration: 15\n",
      "loss:    8.95 y0:   14.07 done: 20.00% Iteration: 20\n",
      "loss:    8.66 y0:   14.06 done: 25.00% Iteration: 25\n",
      "loss:    8.65 y0:   14.07 done: 30.00% Iteration: 30\n",
      "loss:    9.99 y0:   14.07 done: 35.00% Iteration: 35\n",
      "loss:    8.15 y0:   14.08 done: 40.00% Iteration: 40\n",
      "loss:   10.14 y0:   14.08 done: 45.00% Iteration: 45\n",
      "loss:    8.81 y0:   14.08 done: 50.00% Iteration: 50\n",
      "loss:    8.48 y0:   14.09 done: 55.00% Iteration: 55\n",
      "loss:    7.55 y0:   14.09 done: 60.00% Iteration: 60\n",
      "loss:    8.06 y0:   14.08 done: 65.00% Iteration: 65\n",
      "loss:    8.31 y0:   14.08 done: 70.00% Iteration: 70\n",
      "loss:    8.11 y0:   14.07 done: 75.00% Iteration: 75\n",
      "loss:    7.76 y0:   14.08 done: 80.00% Iteration: 80\n",
      "loss:    9.32 y0:   14.08 done: 85.00% Iteration: 85\n",
      "loss:    7.57 y0:   14.09 done: 90.00% Iteration: 90\n",
      "loss:    6.98 y0:   14.10 done: 95.00% Iteration: 95\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from parameters import parameters_default\n",
    "\n",
    "par = parameters_default()\n",
    "\n",
    "dim_x, dim_y, dim_d, dim_h = 1, 1, 1, 11\n",
    "\n",
    "guess_sol = [0,27]\n",
    "\n",
    "S0 = par.S0*torch.ones(dim_x)\n",
    "\n",
    "def mu(t, x, y): return par.mu*x\n",
    "\n",
    "def sigma(t, x): return par.sigma*x.reshape(batch_size, dim_x, dim_d)\n",
    "\n",
    "def f_europian(t, x, y, z): return (-par.r*y ).reshape(batch_size, dim_y)\n",
    "\n",
    "def g(x): return torch.max(par.K-x, torch.zeros(batch_size, dim_y, device=device)) \n",
    "\n",
    "fbsde_pars = fbsde_parameters(S0, mu, sigma, f_europian, g, par.T,dim_x, dim_y, dim_d, guess_sol)\n",
    "model = Model(fbsde_pars, dim_h)\n",
    "bsde_solver = BSDEsolver(fbsde_pars, model)\n",
    "\n",
    "torch.manual_seed(46)\n",
    "\n",
    "time_discretizations = [2,10,40]\n",
    "iterations = [100,100,100]\n",
    "batch_sizes = [1000,1000,1000]\n",
    "plotting = False\n",
    "\n",
    "for N,it,batch_size in zip(time_discretizations,iterations,batch_sizes): \n",
    "    print(f\"Time discretization: {N} Batch size: {batch_size} Iterations: {it}\")\n",
    "    loss, y0=bsde_solver.train(batch_size, N,it, log=True)\n",
    "    print(60*\"=\")\n",
    "    if plotting:\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        axs[0].plot(loss)\n",
    "        axs[0].set_title('Loss')\n",
    "\n",
    "        axs[1].plot(y0)\n",
    "        axs[1].set_title('y0')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
