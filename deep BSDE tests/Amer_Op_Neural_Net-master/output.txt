 Number of CPUs:  4
 Simulation size:  10000

 AmericanOption, initialization, phase 1 : 
   0 (0.00, 0.00), 1 (0.00, 0.00), 2 (0.00, 0.00), 3 (0.00, 0.00), 4 (0.00, 0.00), 5 (0.00, 0.00), 6 (0.00, 0.00), 7 (0.00, 0.02), 8 (0.00, 0.00), 9 (0.00, 0.00), 10 (0.00, 0.00), 
 evolution_state, time:  0.02

 AmericanOption, initialization, phase 2 : 
   0 (0.00), 1 (0.00), 2 (0.00), 3 (0.00), 4 (0.02), 5 (0.00), 6 (0.00), 7 (0.00), 8 (0.00), 9 (0.00), 10 (0.00), 
 initialize_results, time:  0.02


************** Main Script: Neural Network **************


 Trainable variables in the main neural network  AmerOp : 
    <tf.Variable 'AmerOp/layer0/batchX/beta:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchX/gamma:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/beta:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/gamma:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/WX:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/WZ:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/alpha:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer7/WZ:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer7/b:0' shape=(1, 1, 1) dtype=float64_ref>

 Global variables in the main neural network  AmerOp : 
    <tf.Variable 'AmerOp/step:0' shape=() dtype=int32_ref>
    <tf.Variable 'AmerOp/init_rate:0' shape=() dtype=float64_ref>
    <tf.Variable 'AmerOp/decay_rate:0' shape=() dtype=float64_ref>
    <tf.Variable 'AmerOp/n_relaxstep:0' shape=() dtype=int32_ref>
    <tf.Variable 'AmerOp/n_decaystep:0' shape=() dtype=int32_ref>
    <tf.Variable 'AmerOp/layer0/batchX/mv_mean:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchX/mv_var:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchX/beta:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchX/gamma:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/mv_mean:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/mv_var:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/beta:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer0/batchZ/gamma:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/WX:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/WZ:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer1/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer2/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer3/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer4/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer5/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/WZ:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/mv_mean:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/mv_var:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/beta:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer6/batchZ/gamma:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/delta:0' shape=() dtype=float64_ref>
    <tf.Variable 'AmerOp/alpha:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer7/WZ:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/layer7/b:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/beta/COCOB:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/beta/COCOB_1:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/beta/COCOB_2:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/beta/COCOB_3:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/beta/COCOB_4:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/gamma/COCOB:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/gamma/COCOB_1:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/gamma/COCOB_2:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/gamma/COCOB_3:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchX/gamma/COCOB_4:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/beta/COCOB:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/beta/COCOB_1:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/beta/COCOB_2:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/beta/COCOB_3:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/beta/COCOB_4:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/gamma/COCOB:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/gamma/COCOB_1:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/gamma/COCOB_2:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/gamma/COCOB_3:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer0/batchZ/gamma/COCOB_4:0' shape=(1, 1, 2) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WX/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WX/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WX/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WX/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WX/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WZ/COCOB:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WZ/COCOB_1:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WZ/COCOB_2:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WZ/COCOB_3:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/WZ/COCOB_4:0' shape=(1, 2, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer1/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/WZ/COCOB:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/WZ/COCOB_1:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/WZ/COCOB_2:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/WZ/COCOB_3:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/WZ/COCOB_4:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer2/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/WZ/COCOB:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/WZ/COCOB_1:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/WZ/COCOB_2:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/WZ/COCOB_3:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/WZ/COCOB_4:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer3/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/WZ/COCOB:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/WZ/COCOB_1:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/WZ/COCOB_2:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/WZ/COCOB_3:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/WZ/COCOB_4:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer4/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/WZ/COCOB:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/WZ/COCOB_1:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/WZ/COCOB_2:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/WZ/COCOB_3:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/WZ/COCOB_4:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer5/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/WZ/COCOB:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/WZ/COCOB_1:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/WZ/COCOB_2:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/WZ/COCOB_3:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/WZ/COCOB_4:0' shape=(1, 7, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/beta/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/beta/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/beta/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/beta/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/beta/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/gamma/COCOB:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/gamma/COCOB_1:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/gamma/COCOB_2:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/gamma/COCOB_3:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer6/batchZ/gamma/COCOB_4:0' shape=(1, 1, 7) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/alpha/COCOB:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/alpha/COCOB_1:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/alpha/COCOB_2:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/alpha/COCOB_3:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/alpha/COCOB_4:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/WZ/COCOB:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/WZ/COCOB_1:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/WZ/COCOB_2:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/WZ/COCOB_3:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/WZ/COCOB_4:0' shape=(1, 7, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/b/COCOB:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/b/COCOB_1:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/b/COCOB_2:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/b/COCOB_3:0' shape=(1, 1, 1) dtype=float64_ref>
    <tf.Variable 'AmerOp/AmerOp/layer7/b/COCOB_4:0' shape=(1, 1, 1) dtype=float64_ref>


************** n =  9  **************


 **** n =  9 , Pre-processing 

 **** n =  9 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  0.020000 ,  gradY :  -0.680009 ,  regloss :  80429.078767
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.911122 ,  b :  0.028902 ,  gradY :  -0.668016 ,  regloss :  98835.961124
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.830064 ,  b :  0.040228 ,  gradY :  -0.634481 ,  regloss :  164968.590501
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.756139 ,  b :  0.047269 ,  gradY :  -0.678893 ,  regloss :  22558.637292
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.688718 ,  b :  0.069132 ,  gradY :  -0.668699 ,  regloss :  136269.608069
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.627230 ,  b :  0.085852 ,  gradY :  -0.619199 ,  regloss :  42987.046376
 step :     7 ,  learning rate:  0.009120 ,  batch learning rate:  0.571151 ,  b :  0.095860 ,  gradY :  -0.731202 ,  regloss :  37998.002172
 step :     8 ,  learning rate:  0.008318 ,  batch learning rate:  0.520008 ,  b :  0.109391 ,  gradY :  -0.617182 ,  regloss :  43168.332243
 step :     9 ,  learning rate:  0.007586 ,  batch learning rate:  0.473364 ,  b :  0.130060 ,  gradY :  -0.644143 ,  regloss :  72792.726112
 step :    10 ,  learning rate:  0.006918 ,  batch learning rate:  0.430824 ,  b :  0.169885 ,  gradY :  -0.707217 ,  regloss :  132945.040314
 step :    11 ,  learning rate:  0.006310 ,  batch learning rate:  0.392027 ,  b :  0.198679 ,  gradY :  -0.646347 ,  regloss :  36515.228912
 step :    12 ,  learning rate:  0.005754 ,  batch learning rate:  0.356645 ,  b :  0.216547 ,  gradY :  -0.645888 ,  regloss :  35597.956261
 step :    13 ,  learning rate:  0.005248 ,  batch learning rate:  0.324375 ,  b :  0.239326 ,  gradY :  -0.584984 ,  regloss :  27432.753216
 step :    14 ,  learning rate:  0.004786 ,  batch learning rate:  0.294945 ,  b :  0.300838 ,  gradY :  -0.587602 ,  regloss :  105346.097129
 step :    15 ,  learning rate:  0.004365 ,  batch learning rate:  0.268104 ,  b :  0.379745 ,  gradY :  -0.610008 ,  regloss :  118257.357079
 step :    16 ,  learning rate:  0.003981 ,  batch learning rate:  0.243625 ,  b :  0.445440 ,  gradY :  -0.619894 ,  regloss :  49019.080136
 step :    17 ,  learning rate:  0.003631 ,  batch learning rate:  0.221300 ,  b :  0.484816 ,  gradY :  -0.633949 ,  regloss :  18436.839324
 step :    18 ,  learning rate:  0.003311 ,  batch learning rate:  0.200939 ,  b :  0.536045 ,  gradY :  -0.684884 ,  regloss :  28537.065213
 step :    19 ,  learning rate:  0.003020 ,  batch learning rate:  0.182370 ,  b :  0.568640 ,  gradY :  -0.704834 ,  regloss :  32475.890908
 step :    20 ,  learning rate:  0.002754 ,  batch learning rate:  0.165434 ,  b :  0.626588 ,  gradY :  -0.658873 ,  regloss :  35293.670538
 step :    21 ,  learning rate:  0.002512 ,  batch learning rate:  0.149989 ,  b :  0.702566 ,  gradY :  -0.624217 ,  regloss :  39316.586571
 step :    41 ,  learning rate:  0.000398 ,  batch learning rate:  0.015272 ,  b :  2.834738 ,  gradY :  -0.683497 ,  regloss :  91198.904660
 step :    61 ,  learning rate:  0.000100 ,  batch learning rate:  -0.000000 ,  b :  4.678138 ,  gradY :  -0.646063 ,  regloss :  116827.657038
 step :    81 ,  learning rate:  0.000100 ,  batch learning rate:  -0.000000 ,  b :  6.158049 ,  gradY :  -0.639753 ,  regloss :  134608.578793
 step :   100 ,  learning rate:  0.000100 ,  batch learning rate:  -0.000000 ,  b :  10.908084 ,  gradY :  -0.703804 ,  regloss :  57497.279289

   time:  5.29

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  11.772610 ,  gradY :  -0.635933 ,  regloss :  157956.901773
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  10.545155 ,  gradY :  -0.604240 ,  regloss :  10786.421761
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  10.730918 ,  gradY :  -0.588520 ,  regloss :  72143.943430
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  10.108821 ,  gradY :  -0.687929 ,  regloss :  10008.145993
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  10.419156 ,  gradY :  -0.649756 ,  regloss :  104878.568232
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  10.576527 ,  gradY :  -0.687105 ,  regloss :  51047.473803
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  10.324161 ,  gradY :  -0.633967 ,  regloss :  55563.107532
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  9.979770 ,  gradY :  -0.695808 ,  regloss :  21146.630485
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  10.222939 ,  gradY :  -0.537269 ,  regloss :  45964.380557
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  11.078617 ,  gradY :  -0.675876 ,  regloss :  108743.778175
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  10.128587 ,  gradY :  -0.586439 ,  regloss :  24766.446908
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  9.738490 ,  gradY :  -0.570542 ,  regloss :  50279.146026
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  10.283477 ,  gradY :  -0.673875 ,  regloss :  49126.454585
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  9.645912 ,  gradY :  -0.632883 ,  regloss :  20910.241853
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  9.497262 ,  gradY :  -0.672342 ,  regloss :  26674.196047
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  10.279516 ,  gradY :  -0.626397 ,  regloss :  90659.152401
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  10.631651 ,  gradY :  -0.577850 ,  regloss :  77070.818637
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  11.196306 ,  gradY :  -0.630121 ,  regloss :  77846.916384
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  10.593655 ,  gradY :  -0.631942 ,  regloss :  56803.971500
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  10.672566 ,  gradY :  -0.623082 ,  regloss :  80865.152409
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  9.099928 ,  gradY :  -0.622634 ,  regloss :  21263.848170
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  7.625525 ,  gradY :  -0.680914 ,  regloss :  59687.273205
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.612728 ,  gradY :  -0.631412 ,  regloss :  15453.391438
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.336985 ,  gradY :  -0.644086 ,  regloss :  43952.804914
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  10.408712 ,  gradY :  -0.681206 ,  regloss :  55792.740586

   time:  0.64

 Ensemble Average :  9
 time: 0.47

 **** n =  9 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  3057

 Evaluate Y and gradY, timestep-wise : 


************** n =  8  **************


 **** n =  8 , Pre-processing 

 **** n =  8 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  6.689045 ,  gradY :  -0.636895 ,  regloss :  83739.205322
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  7.253685 ,  gradY :  -0.623342 ,  regloss :  125500.208555
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  8.933642 ,  gradY :  -0.636689 ,  regloss :  141898.112977
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  7.019960 ,  gradY :  -0.572665 ,  regloss :  90862.678996
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  7.185280 ,  gradY :  -0.598130 ,  regloss :  109110.880864
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  8.440205 ,  gradY :  -0.632528 ,  regloss :  68350.376073
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  8.914140 ,  gradY :  -0.660611 ,  regloss :  99467.908342
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  7.328158 ,  gradY :  -0.541918 ,  regloss :  169250.268607
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  6.882305 ,  gradY :  -0.649643 ,  regloss :  65193.816264
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  6.838113 ,  gradY :  -0.656954 ,  regloss :  112964.176850
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  7.921809 ,  gradY :  -0.644607 ,  regloss :  103604.944543
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  7.672243 ,  gradY :  -0.657306 ,  regloss :  127404.850123
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  8.438106 ,  gradY :  -0.571342 ,  regloss :  172893.678101
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  9.329490 ,  gradY :  -0.678780 ,  regloss :  107353.467030
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  7.044498 ,  gradY :  -0.603330 ,  regloss :  103822.059350
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  9.173215 ,  gradY :  -0.556641 ,  regloss :  155076.548655
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  8.805764 ,  gradY :  -0.594999 ,  regloss :  86991.765744
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  9.428149 ,  gradY :  -0.594790 ,  regloss :  164165.226428
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  7.853383 ,  gradY :  -0.650271 ,  regloss :  110049.710401
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  8.134769 ,  gradY :  -0.629839 ,  regloss :  81738.796470
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  7.509940 ,  gradY :  -0.593381 ,  regloss :  73636.701933
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  3.046785 ,  gradY :  -0.653408 ,  regloss :  67870.336127
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  5.101394 ,  gradY :  -0.623221 ,  regloss :  173297.631898
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  4.375378 ,  gradY :  -0.681128 ,  regloss :  76259.187021
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  5.894591 ,  gradY :  -0.632948 ,  regloss :  77640.977586

   time:  0.75

 Ensemble Average :  1
 time: 0.08

 Ensemble Average :  2
 time: 0.05

 Ensemble Average :  3
 time: 0.08

 Ensemble Average :  4
 time: 0.09

 Ensemble Average :  5
 time: 0.08

 Ensemble Average :  6
 time: 0.09

 Ensemble Average :  7
 time: 0.08

 Ensemble Average :  8
 time: 0.08

 **** n =  8 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  2186

 Evaluate Y and gradY, timestep-wise : 


************** n =  7  **************


 **** n =  7 , Pre-processing 

 **** n =  7 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  6.287662 ,  gradY :  -0.563311 ,  regloss :  100464.621799
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  6.739914 ,  gradY :  -0.652377 ,  regloss :  83332.238594
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  6.839064 ,  gradY :  -0.592390 ,  regloss :  103061.819357
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  6.701882 ,  gradY :  -0.615289 ,  regloss :  99514.672585
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  6.810313 ,  gradY :  -0.603197 ,  regloss :  84285.897467
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  6.829278 ,  gradY :  -0.591738 ,  regloss :  96737.467058
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  6.701888 ,  gradY :  -0.642459 ,  regloss :  92564.970605
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  6.864227 ,  gradY :  -0.617837 ,  regloss :  144258.986570
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  6.963068 ,  gradY :  -0.666314 ,  regloss :  104520.511853
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  7.077264 ,  gradY :  -0.679109 ,  regloss :  162368.577428
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  7.371919 ,  gradY :  -0.651088 ,  regloss :  122920.335913
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  7.408507 ,  gradY :  -0.566429 ,  regloss :  84022.885628
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  7.829413 ,  gradY :  -0.612955 ,  regloss :  129004.112234
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  7.788547 ,  gradY :  -0.549770 ,  regloss :  95620.604012
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  7.743436 ,  gradY :  -0.626675 ,  regloss :  92989.708393
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  7.566858 ,  gradY :  -0.573322 ,  regloss :  68821.118769
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  8.117849 ,  gradY :  -0.651252 ,  regloss :  116833.961541
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  8.106053 ,  gradY :  -0.616171 ,  regloss :  97258.127565
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  8.239110 ,  gradY :  -0.644041 ,  regloss :  167985.301905
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  8.740045 ,  gradY :  -0.707327 ,  regloss :  149530.695984
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  8.108943 ,  gradY :  -0.588974 ,  regloss :  87266.576913
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  8.678593 ,  gradY :  -0.576827 ,  regloss :  140005.217848
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.026992 ,  gradY :  -0.586771 ,  regloss :  102943.608376
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.114356 ,  gradY :  -0.571922 ,  regloss :  119226.997264
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.227789 ,  gradY :  -0.616037 ,  regloss :  127137.855412

   time:  0.64

 Ensemble Average :  7
 time: 0.06

 **** n =  7 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  2744

 Evaluate Y and gradY, timestep-wise : 


************** n =  6  **************


 **** n =  6 , Pre-processing 

 **** n =  6 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  6.131504 ,  gradY :  -0.588813 ,  regloss :  80950.501239
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  6.421919 ,  gradY :  -0.614923 ,  regloss :  102312.632915
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  6.735255 ,  gradY :  -0.618610 ,  regloss :  90479.278557
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  6.462159 ,  gradY :  -0.610136 ,  regloss :  78297.137663
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  6.911756 ,  gradY :  -0.586374 ,  regloss :  81923.214754
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  7.523171 ,  gradY :  -0.624493 ,  regloss :  85418.183137
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  7.649057 ,  gradY :  -0.579307 ,  regloss :  137951.039958
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  7.773513 ,  gradY :  -0.654348 ,  regloss :  119594.774223
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  7.954647 ,  gradY :  -0.709497 ,  regloss :  97133.097220
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  7.761026 ,  gradY :  -0.618689 ,  regloss :  113372.325794
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  8.191040 ,  gradY :  -0.656091 ,  regloss :  103734.882161
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  8.468583 ,  gradY :  -0.650498 ,  regloss :  95482.383480
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  7.428806 ,  gradY :  -0.643869 ,  regloss :  96374.384743
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  7.798509 ,  gradY :  -0.686279 ,  regloss :  94526.034537
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  7.656051 ,  gradY :  -0.653001 ,  regloss :  109500.445186
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  8.370754 ,  gradY :  -0.582908 ,  regloss :  147018.789129
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  8.688312 ,  gradY :  -0.584827 ,  regloss :  106119.868290
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  8.047346 ,  gradY :  -0.618284 ,  regloss :  97647.769384
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  8.358056 ,  gradY :  -0.609192 ,  regloss :  72251.523596
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  8.345333 ,  gradY :  -0.629982 ,  regloss :  99645.892335
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  8.666926 ,  gradY :  -0.610171 ,  regloss :  141083.071958
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  8.489604 ,  gradY :  -0.615672 ,  regloss :  89221.199120
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.541951 ,  gradY :  -0.647829 ,  regloss :  61038.475573
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.146506 ,  gradY :  -0.570519 ,  regloss :  82695.878508
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.451389 ,  gradY :  -0.580299 ,  regloss :  67597.140139

   time:  0.64

 Ensemble Average :  1
 time: 0.06

 Ensemble Average :  2
 time: 0.06

 Ensemble Average :  3
 time: 0.05

 Ensemble Average :  4
 time: 0.08

 Ensemble Average :  5
 time: 0.07

 Ensemble Average :  6
 time: 0.06

 **** n =  6 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  1022

 Evaluate Y and gradY, timestep-wise : 


************** n =  5  **************


 **** n =  5 , Pre-processing 

 **** n =  5 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  6.837736 ,  gradY :  -0.581223 ,  regloss :  115144.892756
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  7.004303 ,  gradY :  -0.627774 ,  regloss :  108221.451208
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  6.842099 ,  gradY :  -0.655486 ,  regloss :  152770.076459
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  7.117746 ,  gradY :  -0.583611 ,  regloss :  124836.719363
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  7.128317 ,  gradY :  -0.643687 ,  regloss :  90386.178391
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  7.208642 ,  gradY :  -0.598092 ,  regloss :  109618.608146
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  7.522856 ,  gradY :  -0.619215 ,  regloss :  121943.864262
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  8.076868 ,  gradY :  -0.604918 ,  regloss :  123227.021959
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  8.094395 ,  gradY :  -0.622354 ,  regloss :  99722.214841
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  8.020444 ,  gradY :  -0.635276 ,  regloss :  111242.233461
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  7.873133 ,  gradY :  -0.633412 ,  regloss :  83599.111788
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  7.728615 ,  gradY :  -0.622424 ,  regloss :  103946.096072
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  7.742486 ,  gradY :  -0.581291 ,  regloss :  109243.280967
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  7.718745 ,  gradY :  -0.586937 ,  regloss :  108143.420988
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  7.668024 ,  gradY :  -0.590375 ,  regloss :  127591.565294
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  7.997582 ,  gradY :  -0.601041 ,  regloss :  157523.579151
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  8.060168 ,  gradY :  -0.602505 ,  regloss :  140394.134771
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  8.148229 ,  gradY :  -0.617113 ,  regloss :  109138.301625
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  7.647587 ,  gradY :  -0.632064 ,  regloss :  108891.832549
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  7.960149 ,  gradY :  -0.610102 ,  regloss :  85005.470619
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  7.814996 ,  gradY :  -0.651655 ,  regloss :  135777.433332
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  7.623646 ,  gradY :  -0.571340 ,  regloss :  94836.455562
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.847218 ,  gradY :  -0.633924 ,  regloss :  129785.209161
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.871570 ,  gradY :  -0.653864 ,  regloss :  115124.263270
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.419989 ,  gradY :  -0.632840 ,  regloss :  100701.769820

   time:  0.64

 Ensemble Average :  5
 time: 0.06

 **** n =  5 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  766

 Evaluate Y and gradY, timestep-wise : 


************** n =  4  **************


 **** n =  4 , Pre-processing 

 **** n =  4 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  8.023498 ,  gradY :  -0.649485 ,  regloss :  160081.605457
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  7.889084 ,  gradY :  -0.607756 ,  regloss :  103332.918321
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  8.174620 ,  gradY :  -0.643090 ,  regloss :  102627.362174
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  7.681545 ,  gradY :  -0.615653 ,  regloss :  97629.755113
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  7.798340 ,  gradY :  -0.610083 ,  regloss :  124194.605418
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  7.649502 ,  gradY :  -0.649083 ,  regloss :  108552.741400
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  7.581599 ,  gradY :  -0.575027 ,  regloss :  115637.901194
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  7.387602 ,  gradY :  -0.577579 ,  regloss :  76497.785585
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  7.912107 ,  gradY :  -0.587769 ,  regloss :  115062.077315
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  7.688923 ,  gradY :  -0.620322 ,  regloss :  110808.622299
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  7.460103 ,  gradY :  -0.637345 ,  regloss :  100771.568488
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  7.822404 ,  gradY :  -0.584977 ,  regloss :  94079.907369
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  7.961135 ,  gradY :  -0.603727 ,  regloss :  129108.185094
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  8.504428 ,  gradY :  -0.635522 ,  regloss :  127762.800331
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  7.664060 ,  gradY :  -0.605070 ,  regloss :  126494.530117
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  8.304575 ,  gradY :  -0.551557 ,  regloss :  147575.437238
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  9.065693 ,  gradY :  -0.594646 ,  regloss :  126812.609028
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  9.661863 ,  gradY :  -0.636074 ,  regloss :  190233.414439
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  9.718495 ,  gradY :  -0.591288 ,  regloss :  148317.201642
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  9.040171 ,  gradY :  -0.632905 ,  regloss :  146479.714610
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  8.975678 ,  gradY :  -0.595326 ,  regloss :  102389.437138
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  8.085055 ,  gradY :  -0.651390 ,  regloss :  150287.032340
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.305022 ,  gradY :  -0.604418 ,  regloss :  158529.147615
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.164020 ,  gradY :  -0.542732 ,  regloss :  110996.472591
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.118595 ,  gradY :  -0.617251 ,  regloss :  158100.182815

   time:  0.66

 Ensemble Average :  1
 time: 0.05

 Ensemble Average :  2
 time: 0.08

 Ensemble Average :  3
 time: 0.06

 Ensemble Average :  4
 time: 0.06

 **** n =  4 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  489

 Evaluate Y and gradY, timestep-wise : 


************** n =  3  **************


 **** n =  3 , Pre-processing 

 **** n =  3 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  8.262639 ,  gradY :  -0.614193 ,  regloss :  113731.820705
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  8.155137 ,  gradY :  -0.586185 ,  regloss :  154305.587826
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  8.472504 ,  gradY :  -0.549430 ,  regloss :  102632.421138
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  8.449488 ,  gradY :  -0.565427 ,  regloss :  128110.731580
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  8.502786 ,  gradY :  -0.536383 ,  regloss :  93238.848617
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  8.461253 ,  gradY :  -0.578919 ,  regloss :  105488.340480
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  8.275066 ,  gradY :  -0.585040 ,  regloss :  92791.118979
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  8.043046 ,  gradY :  -0.574370 ,  regloss :  121798.475056
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  8.234322 ,  gradY :  -0.570368 ,  regloss :  89133.114995
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  8.017564 ,  gradY :  -0.559241 ,  regloss :  88291.465923
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  8.033821 ,  gradY :  -0.591971 ,  regloss :  143959.125649
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  8.345959 ,  gradY :  -0.637535 ,  regloss :  141185.580245
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  8.309253 ,  gradY :  -0.593215 ,  regloss :  94736.765681
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  8.119897 ,  gradY :  -0.594341 ,  regloss :  105978.040567
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  8.272686 ,  gradY :  -0.592268 ,  regloss :  103575.941754
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  8.407587 ,  gradY :  -0.593601 ,  regloss :  134306.758316
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  8.744114 ,  gradY :  -0.561800 ,  regloss :  125615.131826
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  8.596395 ,  gradY :  -0.593596 ,  regloss :  138909.335486
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  8.634663 ,  gradY :  -0.644957 ,  regloss :  132473.084003
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  8.203728 ,  gradY :  -0.563067 ,  regloss :  75785.792307
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  8.500181 ,  gradY :  -0.564232 ,  regloss :  135672.760296
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  7.813723 ,  gradY :  -0.555375 ,  regloss :  110921.692404
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.361594 ,  gradY :  -0.573907 ,  regloss :  136279.255429
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.868928 ,  gradY :  -0.607331 ,  regloss :  93915.557362
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.291650 ,  gradY :  -0.600947 ,  regloss :  109127.862993

   time:  0.66

 Ensemble Average :  3
 time: 0.06

 **** n =  3 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  520

 Evaluate Y and gradY, timestep-wise : 


************** n =  2  **************


 **** n =  2 , Pre-processing 

 **** n =  2 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  7.125604 ,  gradY :  -0.608369 ,  regloss :  158728.182419
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  7.356455 ,  gradY :  -0.581171 ,  regloss :  141510.939865
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  6.992185 ,  gradY :  -0.589858 ,  regloss :  117790.164801
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  6.746045 ,  gradY :  -0.564434 ,  regloss :  113471.254641
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  6.468018 ,  gradY :  -0.567684 ,  regloss :  103639.520562
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  6.408855 ,  gradY :  -0.594286 ,  regloss :  103148.666012
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  6.196802 ,  gradY :  -0.573067 ,  regloss :  101828.667568
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  6.402849 ,  gradY :  -0.603665 ,  regloss :  117987.346776
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  6.049076 ,  gradY :  -0.578643 ,  regloss :  78369.307372
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  6.160677 ,  gradY :  -0.571079 ,  regloss :  110529.847720
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  6.429232 ,  gradY :  -0.582855 ,  regloss :  164350.167041
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  6.307474 ,  gradY :  -0.603648 ,  regloss :  144040.852641
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  6.032115 ,  gradY :  -0.585221 ,  regloss :  115342.079719
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  6.261127 ,  gradY :  -0.526698 ,  regloss :  117120.871775
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  6.172791 ,  gradY :  -0.585780 ,  regloss :  85721.591592
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  5.652001 ,  gradY :  -0.589701 ,  regloss :  114840.357728
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  6.084925 ,  gradY :  -0.542928 ,  regloss :  128127.143523
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  6.051829 ,  gradY :  -0.561736 ,  regloss :  123911.912784
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  5.887032 ,  gradY :  -0.597501 ,  regloss :  114870.386353
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  6.172993 ,  gradY :  -0.557961 ,  regloss :  130752.949258
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  5.671014 ,  gradY :  -0.587446 ,  regloss :  77965.453083
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  6.067203 ,  gradY :  -0.538540 ,  regloss :  112228.933491
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.277886 ,  gradY :  -0.591011 ,  regloss :  103850.080752
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  5.875681 ,  gradY :  -0.563317 ,  regloss :  118193.251391
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  6.012556 ,  gradY :  -0.575689 ,  regloss :  125968.843010

   time:  0.65

 Ensemble Average :  1
 time: 0.06

 Ensemble Average :  2
 time: 0.05

 **** n =  2 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  166

 Evaluate Y and gradY, timestep-wise : 


************** n =  1  **************


 **** n =  1 , Pre-processing 

 **** n =  1 , Neural Network 

 ****  AmerOp , Training : 

 ****  AmerOp , Adam Optimization : 
 step :     1 ,  learning rate:  0.010000 ,  batch learning rate:  1.000000 ,  b :  6.081428 ,  gradY :  -0.576237 ,  regloss :  120129.778086
 step :     2 ,  learning rate:  0.010000 ,  batch learning rate:  0.870834 ,  b :  6.183448 ,  gradY :  -0.576909 ,  regloss :  90676.720424
 step :     3 ,  learning rate:  0.010000 ,  batch learning rate:  0.758336 ,  b :  6.393521 ,  gradY :  -0.584296 ,  regloss :  122028.490995
 step :     4 ,  learning rate:  0.010000 ,  batch learning rate:  0.660354 ,  b :  6.334807 ,  gradY :  -0.544233 ,  regloss :  116615.979232
 step :     5 ,  learning rate:  0.010000 ,  batch learning rate:  0.575015 ,  b :  6.468505 ,  gradY :  -0.574546 ,  regloss :  87799.439424
 step :     6 ,  learning rate:  0.010000 ,  batch learning rate:  0.500688 ,  b :  6.554219 ,  gradY :  -0.563643 ,  regloss :  166361.483842
 step :     7 ,  learning rate:  0.008710 ,  batch learning rate:  0.435952 ,  b :  6.830756 ,  gradY :  -0.550743 ,  regloss :  113725.246370
 step :     8 ,  learning rate:  0.007586 ,  batch learning rate:  0.379569 ,  b :  7.114529 ,  gradY :  -0.546963 ,  regloss :  104429.956968
 step :     9 ,  learning rate:  0.006607 ,  batch learning rate:  0.330462 ,  b :  7.208657 ,  gradY :  -0.564556 ,  regloss :  117955.916016
 step :    10 ,  learning rate:  0.005754 ,  batch learning rate:  0.287691 ,  b :  7.165413 ,  gradY :  -0.588026 ,  regloss :  89793.449128
 step :    11 ,  learning rate:  0.005012 ,  batch learning rate:  0.250439 ,  b :  7.289303 ,  gradY :  -0.586719 ,  regloss :  107569.051728
 step :    12 ,  learning rate:  0.004365 ,  batch learning rate:  0.217994 ,  b :  7.334766 ,  gradY :  -0.595643 ,  regloss :  100916.513839
 step :    13 ,  learning rate:  0.003802 ,  batch learning rate:  0.189736 ,  b :  7.090977 ,  gradY :  -0.561028 ,  regloss :  115802.238544
 step :    14 ,  learning rate:  0.003311 ,  batch learning rate:  0.165124 ,  b :  7.039153 ,  gradY :  -0.562066 ,  regloss :  115045.174953
 step :    15 ,  learning rate:  0.002884 ,  batch learning rate:  0.143688 ,  b :  6.996285 ,  gradY :  -0.576055 ,  regloss :  90018.069522
 step :    16 ,  learning rate:  0.002512 ,  batch learning rate:  0.125018 ,  b :  6.816840 ,  gradY :  -0.538585 ,  regloss :  131161.559983
 step :    17 ,  learning rate:  0.002188 ,  batch learning rate:  0.108757 ,  b :  6.951786 ,  gradY :  -0.531312 ,  regloss :  113181.036011
 step :    18 ,  learning rate:  0.001905 ,  batch learning rate:  0.094594 ,  b :  6.980528 ,  gradY :  -0.570477 ,  regloss :  100414.651351
 step :    19 ,  learning rate:  0.001660 ,  batch learning rate:  0.082259 ,  b :  7.028378 ,  gradY :  -0.565152 ,  regloss :  104119.625123
 step :    20 ,  learning rate:  0.001445 ,  batch learning rate:  0.071515 ,  b :  7.215328 ,  gradY :  -0.553733 ,  regloss :  134662.912154
 step :    21 ,  learning rate:  0.001259 ,  batch learning rate:  0.062158 ,  b :  7.470791 ,  gradY :  -0.572126 ,  regloss :  170773.655429
 step :    41 ,  learning rate:  0.000079 ,  batch learning rate:  0.002984 ,  b :  8.011012 ,  gradY :  -0.603706 ,  regloss :  108753.899563
 step :    61 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.744203 ,  gradY :  -0.575050 ,  regloss :  116634.636015
 step :    81 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  8.082149 ,  gradY :  -0.568842 ,  regloss :  108030.059050
 step :   100 ,  learning rate:  0.000010 ,  batch learning rate:  0.000000 ,  b :  7.505817 ,  gradY :  -0.598152 ,  regloss :  140429.608129

   time:  0.64

 Ensemble Average :  1
 time: 0.06

 **** n =  1 , Post-processing 

 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  21

 Evaluate Y and gradY, timestep-wise : 


************** n =  0  **************


 **** n =  0 , Pre-processing 

 **** n =  0 , Evaluation 

************** Results (Neural Network) **************
 The point X0 to evaluate is:  [100.]
 The price at t=0 is:  16.888024 ;  95% CI: [ 16.763201 17.012847 ]
 The delta at t=0 is:  [-0.576983] 


 Evaluate control (exercise boundary) : 
  Number of in-the-money points :  0

 Evaluate Y and gradY, timestep-wise : 

Total running time :  27.00


************** Evaluation of the Entire Model, nu =  0  **************

************** Results (Simulation values) **************
 The point X0 to evaluate is:  [100.]
 The price at t=0 is:  16.953958 ;  95% CI: [ 16.635729 17.272188 ]
 The delta at t=0 is:  [-0.540077] 



************** Hedging Results (Simulation values) **************


 P & L mean:  -0.04549862892746835 , std:  0.26377851396926916
