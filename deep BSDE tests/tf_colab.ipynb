{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is copy pasted and modified from \n",
    "https://colab.research.google.com/github/janblechschmidt/PDEsByNNs/blob/main/DeepBSDE_Solver.ipynb#scrollTo=MkAvrqE461C-.\n",
    "\n",
    "Can't make it do what I want it to do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DeepBSDE(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 t0=0.0,\n",
    "                 t1=1.0,\n",
    "                 dim=1,\n",
    "                 X0=1.0,\n",
    "                 time_steps=20,\n",
    "                 mu = 0.07,\n",
    "                 r=0.02,\n",
    "                 sigma=0.2,\n",
    "                 learning_rate=1e-2,\n",
    "                 num_hidden_layers=2,\n",
    "                 num_neurons=200,\n",
    "                 DTYPE=\"float32\",\n",
    "                 **kwargs):\n",
    "        \"\"\"Set up basic architecture of deep BSDE NN model.\"\"\"\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.N = time_steps\n",
    "        self.dim = dim\n",
    "        self.r = r\n",
    "        self.DTYPE = DTYPE\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.x = X0*np.ones(self.dim)\n",
    "        self.dt = (t1 - t0)/(self.N)\n",
    "        self.sqrt_dt = np.sqrt(self.dt)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.t_space = np.linspace(self.t0, self.t1, self.N + 1)[:-1]\n",
    "        \n",
    "        tf.keras.backend.set_floatx(self.DTYPE)\n",
    "        # Set optimizer\n",
    "        self.optimizer=tf.keras.optimizers.Adam(self.learning_rate,\n",
    "                                                epsilon=1e-8)\n",
    "        \n",
    "        # Initialize value and gradient of u(t_0,X_{t_0}) by zeros\n",
    "        #self.u0 = tf.Variable(np.zeros((1),dtype=DTYPE))\n",
    "        #self.gradu0 = tf.Variable(np.zeros((1,self.dim),dtype=DTYPE))\n",
    "        \n",
    "        # Alternatively, initialize both randomly\n",
    "        self.u0 = tf.Variable(np.random.uniform(10.0, 20.0,size=(1)).astype(self.DTYPE))\n",
    "        self.gradu0 = tf.Variable(np.random.uniform(-1e-1, 1e-1, size=(1, self.dim)).astype(self.DTYPE))\n",
    "        \n",
    "        # Create template of dense layer without bias and activation\n",
    "        _dense = lambda dim: tf.keras.layers.Dense(\n",
    "            units=dim,\n",
    "            activation=None,\n",
    "            use_bias=False)\n",
    "        \n",
    "        # Create template of batch normalization layer\n",
    "        _bn = lambda : tf.keras.layers.BatchNormalization(\n",
    "            momentum=.99,\n",
    "            epsilon=1e-6,\n",
    "            beta_initializer=tf.random_normal_initializer(0.0, stddev=0.1),\n",
    "            gamma_initializer=tf.random_uniform_initializer(0.1, 0.5))\n",
    "        \n",
    "        \n",
    "        # Initialize a list of networks approximating the gradient of u(t, x) at t_i\n",
    "        self.gradui = []\n",
    "        \n",
    "        # Loop over number of time steps\n",
    "        for _ in range(self.N - 1):\n",
    "            \n",
    "            # Batch normalization on dim-dimensional input\n",
    "            this_grad = tf.keras.Sequential()\n",
    "            this_grad.add(tf.keras.layers.Input(shape = (self.dim,)))\n",
    "            this_grad.add(_bn())\n",
    "            \n",
    "            # Hidden layers of type (Dense -> Batch Normalization -> ReLU)\n",
    "            for _ in range(num_hidden_layers):\n",
    "                this_grad.add(_dense(num_neurons))\n",
    "                this_grad.add(_bn())\n",
    "                this_grad.add(tf.keras.layers.ReLU())\n",
    "                \n",
    "            # Dense layer followed by batch normalization for output\n",
    "            this_grad.add(_dense(self.dim))\n",
    "            this_grad.add(_bn())\n",
    "            self.gradui.append(this_grad)\n",
    "      \n",
    "            \n",
    "    def draw_X_and_dW(self, num_sample):\n",
    "        \"\"\" Method to draw num_sample paths of X. \"\"\"\n",
    "        \n",
    "        # Draw increments of Brownian motion\n",
    "        dW = np.random.normal(loc=0.0, scale=self.sqrt_dt, size=(num_sample, self.dim, self.N)).astype(self.DTYPE)\n",
    "        \n",
    "        # Initialize and set array of paths\n",
    "        X = np.zeros((num_sample, self.dim, self.N+1), dtype=self.DTYPE)\n",
    "        \n",
    "        X[:, :, 0] = np.ones((num_sample, self.dim)) * self.x\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            # This corresponds to the Euler-Maruyama Scheme of GBM\n",
    "            X[:, :, i+1] = X[:, :, i]* (1+ self.mu* self.dt + self.sigma * dW[:, :, i])\n",
    "            \n",
    "        # Return simulated paths as well as increments of Brownian motion\n",
    "        return X, dW\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inp, training=False):\n",
    "        \"\"\"\n",
    "        Method to perform one forward sweep through the network\n",
    "        given inputs: inp - (X, dW)\n",
    "                      training - boolean variable indicating training\n",
    "        \"\"\"\n",
    "        X, dW = inp # uses same dW as X\n",
    "        num_sample = X.shape[0]\n",
    "        \n",
    "        \n",
    "        e_num_sample = tf.ones(shape=[num_sample, 1], dtype=self.DTYPE)\n",
    "        \n",
    "        # Value approximation at t0\n",
    "        y = e_num_sample * self.u0\n",
    "        \n",
    "        # Gradient approximation at t0\n",
    "        z = e_num_sample * self.gradu0\n",
    "        \n",
    "        for i in range(self.N-1):\n",
    "            \n",
    "            t = self.t_space[i]\n",
    "            \n",
    "            # Optimal control is attained by gradient\n",
    "            eta1 = self.fun_f(t, X[:, :, i], y, z) * self.dt\n",
    "            eta2 = -tf.reduce_sum(z * dW[:, :, i], axis=1, keepdims=True)\n",
    "            # here we are using the same dW\n",
    "\n",
    "            y = y + eta1 + eta2\n",
    "\n",
    "            # New gradient approximation\n",
    "            # The division by self.dim acts as a stabilizer\n",
    "            z = self.gradui[i](X[:, :, i + 1], training=training) / self.dim\n",
    "\n",
    "        # Final step\n",
    "        eta1 = - self.fun_f(self.t_space[self.N-1], X[:, :, self.N-1], y, z) * self.dt\n",
    "        eta2 = tf.reduce_sum(z * dW[:, :, self.N-1], axis=1, keepdims=True)\n",
    "\n",
    "        y = y + eta1 + eta2\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss_fn(self, inputs, training=False):\n",
    "        X, _ = inputs\n",
    "        # Forward pass to compute value estimates\n",
    "        y_pred = self.call(inputs, training)\n",
    "        \n",
    "        # Exact values at final time\n",
    "        y = self.fun_g(X[:, :, -1])\n",
    "        loss = tf.reduce_mean(tf.square(y-y_pred)) #MSE\n",
    "        \n",
    "        return loss \n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, inp):\n",
    "        loss, grad = self.grad(inp, training=True)\n",
    "        self.optimizer.apply_gradients(zip(grad, self.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def grad(self, inputs, training=False):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_fn(inputs, training=training)\n",
    "        grad = tape.gradient(loss, self.trainable_variables)\n",
    "        return loss, grad\n",
    "    \n",
    "    def fun_f(self, t, x, y, z):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def fun_g(self, t, x, y, z):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class AmericanPut(DeepBSDE):\n",
    "    def __init__(self,K=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.K = K\n",
    "    # driver function\n",
    "\n",
    "    @tf.function\n",
    "    def q(self, x, y):\n",
    "        return self.r * self.K * tf.cast(y <= self.fun_g(x), dtype=self.DTYPE)\n",
    "\n",
    "    @tf.function\n",
    "    def fun_f(self, t, x, y, z):\n",
    "        return -self.r*y + self.q(x,y) \n",
    "\n",
    "    # Terminal/Final cost or payoff\n",
    "    @tf.function\n",
    "    def fun_g(self, x):\n",
    "        return tf.maximum(self.K - x, 0)\n",
    "    \n",
    "\n",
    "def experiment(model, sol,num_epochs=100,batch_size=100):\n",
    "    # Initialize header\n",
    "    print('  Iter        Loss        y   L1_rel    L1_abs   |   Time  Stepsize')\n",
    "     \n",
    "    # Init timer and history list\n",
    "    t0 = time()\n",
    "    history=[]\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        inp = model.draw_X_and_dW(batch_size)\n",
    "        loss = model.train(inp)\n",
    "\n",
    "        # Get current Y_0 \\approx u(0,x)\n",
    "        y = model.u0.numpy()[0]\n",
    "\n",
    "        currtime = time() - t0\n",
    "        l1abs = np.abs(y - sol)\n",
    "        l1rel = l1abs / sol\n",
    "\n",
    "        hentry = (i, loss.numpy(), y, l1rel, l1abs, currtime, model.learning_rate)\n",
    "        history.append(hentry)\n",
    "        if i%10 == 0:\n",
    "            print('{:5d} {:12.4f} {:8.4f} {:8.4f}  {:8.4f}   | {:6.1f}  {:6.2e}'.format(*hentry))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = AmericanPut(K=110, \n",
    "                   X0=100, \n",
    "                   time_steps=5, \n",
    "                   dim=1, \n",
    "                   r= 0.02,\n",
    "                   mu=0.07, \n",
    "                   t0 =0,\n",
    "                   t1 = 1,\n",
    "                   sigma=0.3, \n",
    "                   learning_rate=1e-2, \n",
    "                   num_hidden_layers=2, \n",
    "                   num_neurons=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test, sol = 15.20, num_epochs=100, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
