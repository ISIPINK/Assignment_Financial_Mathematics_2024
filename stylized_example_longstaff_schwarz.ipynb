{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See 1. A Numerical Example in Valuing American Options by Simulation: A Simple Least-Squares Approach Francis A. Longstaff UCLA Eduardo S. Schwartz UCLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   0.07 0.18 0.   0.2  0.09 0.  ]\n",
      "model.coef_ -1.0699876552910912 [ 2.98341063 -1.81357618]\n",
      "interpolated [0.03674056 0.04589834 0.11752682 0.15196921 0.15641792]\n",
      "exercise [0.02 0.03 0.13 0.33 0.26]\n",
      "model.coef_ 2.037512342379653 [-3.3354434   1.35645659]\n",
      "interpolated [0.01348511 0.10874928 0.28606468 0.11700927 0.15276213]\n",
      "exercise [0.01 0.17 0.34 0.18 0.22]\n",
      "model.coef_ 0.11443433004505696 [0. 0.]\n",
      "interpolated [0.11443433 0.11443433 0.11443433 0.11443433 0.11443433 0.11443433\n",
      " 0.11443433 0.11443433]\n",
      "exercise [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "0.11443433004505696 0.03922691623092562\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "paths = np.array([[1.00, 1.09, 1.08, 1.34],\n",
    "                 [1.00, 1.16, 1.26, 1.54],\n",
    "                 [1.00, 1.22, 1.07, 1.03],\n",
    "                 [1.00, 0.93, 0.97, 0.92],\n",
    "                 [1.00, 1.11, 1.56, 1.52],\n",
    "                 [1.00, 0.76, 0.77, 0.90],\n",
    "                 [1.00, 0.92, 0.84, 1.01],\n",
    "                 [1.00, 0.88, 1.22, 1.34]])\n",
    "\n",
    "def least_square_Monte_Carlo_test(paths,r,dt,T,payoff,K):\n",
    "    value = payoff(paths[:,-1])\n",
    "    print(value)\n",
    "    for col in paths.T[:-1][::-1]:# stepping backwards in time\n",
    "       value *= np.exp(-r*dt) # discounting \n",
    "       ITMmask = col < K # selects paths ITM\n",
    "       ITMpaths = col[ITMmask]\n",
    "       ITMvalue = value[ITMmask]\n",
    "       model = LinearRegression()\n",
    "       X = np.column_stack((ITMpaths,ITMpaths**2))\n",
    "       model.fit(X,ITMvalue) # LS of the continuation value\n",
    "       interpolated = model.predict(X)\n",
    "       exercised = payoff_put(ITMpaths,K)\n",
    "    #  value[mask] = np.maximum(interpolated,exercise) see note in paper\n",
    "       value[ITMmask] = np.where(interpolated>exercised, value[ITMmask], exercised)\n",
    "       print(f\"model.coef_ {model.intercept_} {model.coef_}\")\n",
    "       print(f\"interpolated {interpolated}\")\n",
    "       print(f\"exercise {exercised}\")\n",
    "\n",
    "    return np.mean(value), np.std(value)/np.sqrt(len(value))\n",
    "    \n",
    "def payoff_put(S,K): return np.maximum(K-S,0)\n",
    "\n",
    "T = 3\n",
    "dt =1 \n",
    "r = 0.06\n",
    "K = 1.10\n",
    "\n",
    "val,std = least_square_Monte_Carlo_test(paths,r,dt,T,lambda S: payoff_put(S,K),K)\n",
    "print(val,std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
